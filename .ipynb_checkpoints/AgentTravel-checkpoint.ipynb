{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import googlemaps\n",
    "import pprint\n",
    "import json\n",
    "import urllib.parse as parse\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import config\n",
    "from geopy.distance import vincenty\n",
    "\n",
    "MAPS_KEY = config.MAPS_KEY\n",
    "gmaps = googlemaps.Client(key=MAPS_KEY)\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>date</th>\n",
       "      <th>addr_lat</th>\n",
       "      <th>addr_lon</th>\n",
       "      <th>agent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1110988</td>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>40.780602</td>\n",
       "      <td>-73.956398</td>\n",
       "      <td>98438.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1272052</td>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>40.758301</td>\n",
       "      <td>-73.959503</td>\n",
       "      <td>12749.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1280705</td>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>40.593800</td>\n",
       "      <td>-73.974503</td>\n",
       "      <td>234944.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1222165</td>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>40.770401</td>\n",
       "      <td>-73.963699</td>\n",
       "      <td>107927.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1238968</td>\n",
       "      <td>2018-09-12</td>\n",
       "      <td>40.709099</td>\n",
       "      <td>-74.013702</td>\n",
       "      <td>212974.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id        date   addr_lat   addr_lon  agent_id\n",
       "0     1110988  2018-09-12  40.780602 -73.956398   98438.0\n",
       "1     1272052  2018-09-12  40.758301 -73.959503   12749.0\n",
       "2     1280705  2018-09-12  40.593800 -73.974503  234944.0\n",
       "3     1222165  2018-09-12  40.770401 -73.963699  107927.0\n",
       "4     1238968  2018-09-12  40.709099 -74.013702  212974.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('listing_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seems like some agent's ids are missing. Since the exercise states that we need to identify the agent who has travelled the most in one day between two listings, I will be dropping those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "listing_id    399391\n",
       "date          399391\n",
       "addr_lat      399391\n",
       "addr_lon      399391\n",
       "agent_id      399274\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Very interesting to see that there aren't many unique values. I am assuming because agents can show the same apartment until it is off the market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "listing_id    17421\n",
       "date             17\n",
       "addr_lat       4518\n",
       "addr_lon       4558\n",
       "agent_id       8423\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sorting by the dates and agent in order to loop through the rows. Dropped N/As "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>listing_id</th>\n",
       "      <th>date</th>\n",
       "      <th>addr_lat</th>\n",
       "      <th>addr_lon</th>\n",
       "      <th>agent_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110132</td>\n",
       "      <td>1331217</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>40.763302</td>\n",
       "      <td>-73.970100</td>\n",
       "      <td>7335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110235</td>\n",
       "      <td>1341962</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>40.763302</td>\n",
       "      <td>-73.970100</td>\n",
       "      <td>7335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>163089</td>\n",
       "      <td>1350380</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>40.763302</td>\n",
       "      <td>-73.970100</td>\n",
       "      <td>7335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>381637</td>\n",
       "      <td>1330931</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>40.765598</td>\n",
       "      <td>-73.976898</td>\n",
       "      <td>7335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62443</td>\n",
       "      <td>1352194</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>40.780300</td>\n",
       "      <td>-73.986900</td>\n",
       "      <td>7337.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>128146</td>\n",
       "      <td>1305816</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>40.769100</td>\n",
       "      <td>-73.981598</td>\n",
       "      <td>7340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>256850</td>\n",
       "      <td>1317380</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>40.769100</td>\n",
       "      <td>-73.981598</td>\n",
       "      <td>7340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>288710</td>\n",
       "      <td>1357088</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>40.769100</td>\n",
       "      <td>-73.981598</td>\n",
       "      <td>7340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>319500</td>\n",
       "      <td>1283629</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>40.769100</td>\n",
       "      <td>-73.981598</td>\n",
       "      <td>7340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>381517</td>\n",
       "      <td>1325545</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>40.769100</td>\n",
       "      <td>-73.981598</td>\n",
       "      <td>7340.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  listing_id        date   addr_lat   addr_lon  agent_id\n",
       "0  110132     1331217  2018-09-01  40.763302 -73.970100    7335.0\n",
       "1  110235     1341962  2018-09-01  40.763302 -73.970100    7335.0\n",
       "2  163089     1350380  2018-09-01  40.763302 -73.970100    7335.0\n",
       "3  381637     1330931  2018-09-01  40.765598 -73.976898    7335.0\n",
       "4   62443     1352194  2018-09-01  40.780300 -73.986900    7337.0\n",
       "5  128146     1305816  2018-09-01  40.769100 -73.981598    7340.0\n",
       "6  256850     1317380  2018-09-01  40.769100 -73.981598    7340.0\n",
       "7  288710     1357088  2018-09-01  40.769100 -73.981598    7340.0\n",
       "8  319500     1283629  2018-09-01  40.769100 -73.981598    7340.0\n",
       "9  381517     1325545  2018-09-01  40.769100 -73.981598    7340.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_df = df.sort_values(by=['date', 'agent_id']).dropna().reset_index()\n",
    "sorted_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discovered that there were rows with Latitude of 1. Made assumption that latitude 1 (country = Colombia) is not a StreetEasy listing so dropping those rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_asc = df.sort_values(by=[ 'date', 'agent_id'], ascending=True).dropna().reset_index()\n",
    "sorted_asc = sorted_asc.drop(sorted_asc[sorted_asc.addr_lat == 1].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looping through the sorted rows and collected the first address as the origin and the following row if it matched date and agent made it the destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 321740/399266 [00:26<00:06, 12080.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching agent and date for row:  319252\n",
      "No matching agent and date for row:  319253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 325644/399266 [00:26<00:06, 12079.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching agent and date for row:  323859\n",
      "No matching agent and date for row:  323860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 345274/399266 [00:28<00:04, 12070.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching agent and date for row:  343906\n",
      "No matching agent and date for row:  343907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 350559/399266 [00:29<00:04, 12084.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching agent and date for row:  348508\n",
      "No matching agent and date for row:  348509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 370004/399266 [00:30<00:02, 12066.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching agent and date for row:  368565\n",
      "No matching agent and date for row:  368566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 375216/399266 [00:31<00:01, 12071.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching agent and date for row:  373159\n",
      "No matching agent and date for row:  373160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 394706/399266 [00:32<00:00, 12060.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching agent and date for row:  393201\n",
      "No matching agent and date for row:  393202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 399266/399266 [00:33<00:00, 12069.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No matching agent and date for row:  397793\n",
      "No matching agent and date for row:  397794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "origins = []\n",
    "destinations = []\n",
    "agent_id = []\n",
    "date = []\n",
    "\n",
    "for i in tqdm(range(sorted_asc['listing_id'].count())):\n",
    "    try:\n",
    "        if sorted_asc['date'][i] == sorted_asc['date'][i+1] and sorted_asc['agent_id'][i] == sorted_asc['agent_id'][i+1]:\n",
    "            origins.append(str(sorted_asc['addr_lat'][i]) + \",\" + str(sorted_asc['addr_lon'][i]))\n",
    "            destinations.append(str(sorted_asc['addr_lat'][i+1])+ \",\" + str(sorted_asc['addr_lon'][i+1]))\n",
    "            agent_id.append(sorted_asc['agent_id'][i])\n",
    "            date.append(sorted_asc['date'][i])\n",
    "        else:\n",
    "            continue\n",
    "    except KeyError:\n",
    "        print(\"No matching agent and date for row: \", i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### At first I was going to try to loop all the address and make API calls to Google Maps but the performance was not great. Then I thought I could just calculate the distance using geopy functions and came accross the vincenty formula which takes into account Eart being an oblate ellipsoid!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 267161/267161 [00:11<00:00, 22488.71it/s]\n"
     ]
    }
   ],
   "source": [
    "vin_dist = []\n",
    "for o in tqdm(range(len(origins))):\n",
    "    vin_dist.append(vincenty(origins[o], destinations[o]).miles)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Returning the data for the two points in which the distance was the greatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index of max value:  65535\n",
      "40.85630035,-73.86599731 40.53900146,-74.21549988 176009.0 2018-09-05\n"
     ]
    }
   ],
   "source": [
    "max_dist = np.argmax(vin_dist)\n",
    "print('index of max value: ', max_dist)\n",
    "print(origins[max_dist], destinations[max_dist], agent_id[max_dist], date[max_dist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Made Google Maps API call to obtain Driving directions for the locations. Assumed that the agent didn't walk from the Bronx to Staten Island"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On 2018-09-05 Agent: 176009.0 had to travel for  1 hour 0 mins . Making it the agent who travelled the longest in one day\n"
     ]
    }
   ],
   "source": [
    "gmap = gmaps.directions(origin = origins[max_dist], destination = destinations[max_dist], mode='driving')\n",
    "print(\"On\" , date[max_dist] , \"Agent:\", agent_id[max_dist], \"had to travel for \", gmap[0]['legs'][0]['duration']['text'], \". Making it the agent who travelled the longest in one day\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cheers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
